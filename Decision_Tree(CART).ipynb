{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cv_Hgy1Qkx-Q"
   },
   "source": [
    "Decision Trees in Python with Scikit-Learn\n",
    "-------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1KaJTSb3kx-W",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Introduction\n",
    "-----------------\n",
    "A decision tree is one of most frequently and widely **used supervised machine learning algorithms that can perform both regression and classification tasks**. Hence called <font color='green'><b>CART</b> - <u>C</u>lassification <u>A</u>nd <u>R</u>egression <u>T</u>rees.</font>\n",
    "\n",
    "For each attribute in the dataset, the decision tree algorithm forms a node, where the most important attribute is placed at the root node. For evaluation we start at the root node and work our way down the tree by following the corresponding node that meets our condition or \"decision\". This process continues until a leaf node is reached, which contains the prediction or the outcome of the decision tree.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vQZQZTEvkx-Y"
   },
   "source": [
    ">**Advantages of Decision Trees**\n",
    "------------------------------\n",
    "\n",
    "There are several advantages of using decision trees for predictive analysis:\n",
    "\n",
    "1> Decision trees can be used to predict both continuous and discrete values i.e. they work well for both regression and classification tasks.\n",
    "\n",
    "2> They require relatively less effort for training the algorithm.\n",
    "\n",
    "3> They can be used to classify non-linearly separable data.\n",
    "\n",
    "4> They're very fast and efficient compared to KNN and other classification algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yf0e33p2kx-a"
   },
   "source": [
    "# 1. Decision Tree for Classification\n",
    "---------------------------------------------------------\n",
    "<b><font color='green'> We will be using DecisionTreeClassifier from sklearn.tree.</b> It is fast, simple and takes care of all the Math part.\n",
    "<font color='red'>\n",
    "Here, we will predict whether a <b>bank note is authentic or fake</b> depending upon the four different attributes of the image of the note. The <u>attributes</u> are Variance of wavelet transformed image, curtosis of the image, entropy, and skewness of the image.</font>\n",
    "\n",
    "**Note :** In the dataset the **class** variable can be **0 or 1**. **0 indicates authentic BankNote and 1 indicates fake BankNote.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "O6tRpZ9Ekx-c",
    "outputId": "351e329d-c19d-4dfe-8195-d85c9ee7b6bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1372, 5)\n",
      "------------\n",
      "      Variance  Skewness  Curtosis  Entropy  Class\n",
      "1058  -1.56210   -2.2121   4.25910  0.27972      1\n",
      "714    2.55590    3.3605   2.03210  0.26809      0\n",
      "1061  -2.31470    3.6668  -0.69690 -1.24740      1\n",
      "399    2.96950    5.6222   0.27561 -1.15560      0\n",
      "382    0.86202    2.6963   4.29080  0.54739      0\n",
      "376    3.23030    7.8384  -3.53480 -1.21510      0\n",
      "987   -0.55648    3.2136  -3.30850 -2.79650      1\n",
      "416    4.34830   11.1079  -4.08570 -4.25390      0\n",
      "945   -1.76970    3.4329  -1.21440 -2.37890      1\n",
      "595    3.18360    7.2321  -1.07130 -2.59090      0\n"
     ]
    }
   ],
   "source": [
    "# doing the minimum necessary imports\n",
    "# more modules would be imported as and when needed\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "\n",
    "# reading data from CSV file. \n",
    "# reading bank currency note data into pandas dataframe.\n",
    "bankdata = pd.read_csv(\"bill_authentication.csv\")  \n",
    "\n",
    "# Exploratory Data Analysis\n",
    "print(bankdata.shape)  \n",
    "print(\"------------\")\n",
    "\n",
    "#bankdata.head()\n",
    "\n",
    "# shuffling the 100% of the data\n",
    "print(bankdata.sample(random_state=100, frac=1).head(10)) \n",
    "\n",
    "## shuffle the original dataframe\n",
    "# bankdata = bankdata.sample(random_state=100, frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1372 entries, 0 to 1371\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Variance  1372 non-null   float64\n",
      " 1   Skewness  1372 non-null   float64\n",
      " 2   Curtosis  1372 non-null   float64\n",
      " 3   Entropy   1372 non-null   float64\n",
      " 4   Class     1372 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 53.7 KB\n"
     ]
    }
   ],
   "source": [
    "bankdata.info()  # this helps in finding any missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Analysis : </b> Their is no missing data. This data is clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "Y6GpyoWbkx-l",
    "outputId": "2e333fdf-68b0-43c0-e792-f7e47b086483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[197   1]\n",
      " [  3 142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       198\n",
      "           1       0.99      0.98      0.99       145\n",
      "\n",
      "    accuracy                           0.99       343\n",
      "   macro avg       0.99      0.99      0.99       343\n",
      "weighted avg       0.99      0.99      0.99       343\n",
      "\n",
      "0.9883381924198251\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "# Data preprocessing involves \n",
    "# (1) Dividing the data into attributes and labels and \n",
    "# (2) dividing the data into training and testing sets.\n",
    "\n",
    "# To divide the data into attributes and labels, do :\n",
    "X = bankdata.drop('Class', axis=1)  \n",
    "y = bankdata['Class']  \n",
    "\n",
    "# the final preprocessing step is to divide data into training and test sets\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=100)\n",
    "# default test_size parameter value is 0.25\n",
    "\n",
    "# Training the Algorithm. Here we would use DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "classifier = DecisionTreeClassifier()  \n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluating the Algorithm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score  \n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tBVpS6lkx-r"
   },
   "source": [
    "<b><font color='green'>Analysis</font></b> : From the confusion matrix, you can see that out of 343 test instances, our algorithm misclassified only 4. This is approx 99% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6UawJQMEkx-t"
   },
   "source": [
    "# 2. Decision Tree for Regression\n",
    "------------------------------------------------------\n",
    "<b><font color='green'>( We will be using DecisionTreeRegressor from sklearn.tree.</b> It is fast, simple and takes care of all the Math part.  )</font><br><br>\n",
    "<font color='red'>\n",
    "We will use petrol_consumption.csv dataset and <b>try to predict gas consumptions</b> (in millions of gallons) in 48 US states <u>based upon</u> gas tax (in cents), per capita income (dollars), paved highways (in miles) and the proportion of population with a drivers license. </font>\n",
    "\n",
    "**Note :** In the dataset **Petrol_Consumption** is the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "ll3ehD5ckx-v",
    "outputId": "1af6e748-2721-4260-dde9-43acb9a19e71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petrol_tax</th>\n",
       "      <th>Average_income</th>\n",
       "      <th>Paved_Highways</th>\n",
       "      <th>Population_Driver_licence(%)</th>\n",
       "      <th>Petrol_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3571</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.525</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4092</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.572</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3865</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.580</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.5</td>\n",
       "      <td>4870</td>\n",
       "      <td>2351</td>\n",
       "      <td>0.529</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4399</td>\n",
       "      <td>431</td>\n",
       "      <td>0.544</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Petrol_tax  Average_income  Paved_Highways  Population_Driver_licence(%)  \\\n",
       "0         9.0            3571            1976                         0.525   \n",
       "1         9.0            4092            1250                         0.572   \n",
       "2         9.0            3865            1586                         0.580   \n",
       "3         7.5            4870            2351                         0.529   \n",
       "4         8.0            4399             431                         0.544   \n",
       "\n",
       "   Petrol_Consumption  \n",
       "0                 541  \n",
       "1                 524  \n",
       "2                 561  \n",
       "3                 414  \n",
       "4                 410  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "\n",
    "# Importing the Dataset\n",
    "dataset = pd.read_csv('petrol_consumption.csv')\n",
    "\n",
    "dataset.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "gIUQEWChkx-1",
    "outputId": "7f9cd588-94d1-4205-eb0f-aba2203b410a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.67708333333334"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see statistical details of the dataset, execute the following command:\n",
    "\n",
    "#dataset.describe()\n",
    "dataset['Petrol_Consumption'].mean()*0.1 # avg of the target var. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "g07wwXIJkx-7",
    "outputId": "48eda98f-55ae-470f-bc13-6390aab12085"
   },
   "outputs": [],
   "source": [
    "# Preparing the Data\n",
    "# divide the data into attributes and labels\n",
    "X = dataset.drop('Petrol_Consumption', axis=1)  \n",
    "y = dataset['Petrol_Consumption']  \n",
    "\n",
    "# dividing data into training and testing set\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=0)  \n",
    "\n",
    "# Training and Making Predictions\n",
    "# Note : we will using DecisionTreeRegressor class, not DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "Regressor = DecisionTreeRegressor()  \n",
    "Regressor.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = Regressor.predict(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R7Qb5-wHkx_E"
   },
   "source": [
    "**Note** : \n",
    "\n",
    "that in your case the records compared may be different, depending upon the training and testing split. Since the train_test_split method randomly splits the data we likely won't have the same training and test sets. For train_test_split with random_state=0 , you would get the same results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "de1cezwZkx_G",
    "outputId": "f343068b-8295-425f-ead9-d7b165df0158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 51.7\n",
      "Mean Squared Error: 4686.9\n",
      "Root Mean Squared Error: 68.46093776745977\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the Algorithm\n",
    "from sklearn import metrics  \n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ETW50UXNkx_L"
   },
   "source": [
    "The root mean squared error for our algorithm is 68.46, which is more than *10 percent of the mean* of all the values in the '**Petrol_Consumption**' column ( i.e **57.6** ). This means that our algorithm did not do a fine prediction job. \n",
    "Their could many reasons for a Regression Algo to not perform that well, some reasons are : \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "7_Decision_(CART)_trees",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
